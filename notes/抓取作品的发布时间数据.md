# 抓取作品的发布时间数据

## 目的

当用户设置了时间范围时，优化抓取效率。

假如用户设置了时间范围（如设置抓取 2022-2023 年的作品）：

以前下载器会对抓取到的所有作品发出请求，以获取它们的发表日期。

现在我打算在下载器内置一些作品的时间数据，这样在抓取作品之前，根据它的 id 就可以知道它大致的发表日期，这样可以提前判断出不符合条件的作品，不需要去抓取它们。这样就可以提高抓取效率。

## 启动抓取

抓取作品数据的代码保存在 `WorkPublishTime.ts` 里。

先在 `bindEvents` 里设置抓取的 id 范围，然后编译代码，刷新扩展，最后在页面上输入指令来执行抓取。

- `ppdtask1` 抓取图像作品
- `ppdtask2` 抓取小说作品

## 抓取中的细节

下载器会每隔 10000 个作品就抓取一次，保存它的 id 和发布时间。

![](./images/20221030_040331.png)

如果某次要抓取的作品是 404，下载器就会把 id + 1，尝试继续抓取，直到抓取到一个有数据的作品。

当指定范围内的作品全部抓取完成后，下载器会把抓取结果输保存到一个 JSON 文件里下载下来。

保存图像和小说数据的文件名格式如下：

- `workPublishTime-illusts-1-102324813.json`
- `workPublishTime-novels-1-18628857.json`

把里面的数据分别复制（或追加）到 `src\ts\store\WorkPublishTimeIllusts.ts` 和 `src\ts\store\WorkPublishTimeNovels.ts` 里面保存，以供使用。

---------------

由于 404 的作品比正常作品数量还多，所以抓取时发出的请求会增加很多。

早期的作品（id 小于 10000000 以内的作品）里我认为被删除的作品超过了一半。有时候 60 个请求里只有 20 个有效作品，这个比例比较常见，就是只有 1/3 的请求有效。比较糟糕的时候，90 个请求里只有 20 个有效作品。

下面这次抓取，连续 21 个作品都是 404：

![](./images/20221030_041027.png)

近期的作品被删除的比例没有那么高，在 90,000,000 的 id 附近，大约只有 1/3 的请求是 404。

-----------

一开始我打算每隔 1000 个作品抓取一次，但是后来我改为间隔 10000 个了。原因：

1. 间隔 1000 的话要抓取的作品数量太多了（会有超过 100000 条数据）。由于 pixiv 现在有 429 限制，抓取只能以慢速进行，将会花费至少数十小时。雪上加霜的是，由于以前的作品有许多被删除了，下载器会抓取到很多 404 的作品，这些无效请求大大增加了抓取所需的时间。当我抓取了 8 小时之后，才此时抓取到了 id 4400000，只抓取完了 1/25。
2. 更重要的是，当我对比此时获取到的前后两个作品的发布时间时（间隔 1000 个作品），我发现它们的间隔时间通常在 1-3 小时之间。从设计此功能的目的考虑，并不需要把时间精确到 3 小时之内，大致精确到天数就行了。所以间隔 10000 个也能满足需求，而且抓取花费的时间也会少的多。同时数据的体积也会减少很多。

每过一定时间，下载器需要对新增的作品进行抓取，把它们的发布时间数据追加到数据源里。

在后续进行更新时，需要避免抓取到重复的数据。

把起始 id 设置为上次记录中的最后一个 id + 10000，截止 id 设置为现在最新的作品的 id。

## 数据量和文件体积

抓取图像作品，1-102324813，花费了接近 12 个小时，共 10233 条数据。

一开始的数据结构是对象数组，未格式化，体积约为 370KiB。

```js
[{"id":20,"time":1189343647000},{"id":10000,"time":1190285376000},]
```

之后我将其转换为二维数组，以减小体积，这样体积变成了 249KiB，体积减少了三分之一。（代码格式化之后为 289KiB）

```js
[[20,1189343647000],[10000,1190285376000],[20006,1190613767000],]
```

其实还有能进一步减小体积的办法，就是把时间末尾的毫秒部分去掉。

由于 pixiv 的时间戳里只精确到秒，所以毫秒部分全都是 `000`。如果删除毫秒部分，可以再减少 30KiB 体积，接近 1/8。

由于这个比例比较小，必要性不大，所以我没有这么做。

*没有必要将其转换成 Map 结构，因为此数据在使用时需要通过数组下标直接取值。*

-----------------

抓取小说作品，1-18628857，共 1863 条数据。

数据结构也是上面的二维数组，体积约 45KiB。（代码格式化之后为 52KiB）

-----------------

图像和小说的数据合起来约 315KiB，还算能接受。在未来也不会大幅增加。

如果按一开始 1000 个作品间隔来抓取的话，体积就会超过 3MiB 了，那就不太适合内嵌了。

## 使用方法

对于任意作品 id，例如 `67507815`，首先计算它相对于作品间隔的倍数（向下取整）：

```js
Math.floor(67507815/10000)
// 6750
```

使用倍数作为下标，从数据源中取出对应的数据：

```js
// data[6750]
[67500003, 1519767915000]
```

这个数据是数据源里较为接近指定 id 的数据。

*因为数据的 id 一般是整万，或者比整万稍微多一点点，所以它的 id 通常会比指定 id 小。（但如果指定 id 也是整万或者出头，那么这个 id 可能会比指定 id 大一点点。）*

*使用这个下标取数据的方法的前提是，每两个数据之间的 id 相差不会超过指定间隔（10000）。也就是说如果有连续 10000 个作品都是无效作品（如404），就会导致缺少一条应有的数据。目前并未有此种极端情况。即使出现此情况，只要检查出来之后手动补上一条伪造的记录即可。*

--------------

然后取出时间区间：

- 如果这个 id 比指定 id 小，就取这个 id 的时间和下一个 id 的时间来作为时间区间。
- 如果这个 id 比指定 id 大，就取这个 id 的时间和上一个 id 的时间来作为时间区间。

如果时间区间符合用户设置的时间范围，那么就抓取指定 id 的作品，获取它的详细数据再做判断。

如果时间区间不符合用户设置的时间范围，就无需抓取指定 id 的作品，直接跳过它即可，这就达到了节约时间的目的。

## 一些特殊情况的处理

如果按照正常途径获取了作品发布的时间，那么可以得到。但是。这就导致了一些问题。

在初次应用这个优化措施之后，有用户报告了问题：

https://github.com/xuejianxianzun/PixivBatchDownloader/issues/270

从这个 issue 里我发现了一些情况下数据可能造成误判，需要进行处理。这些问题的根源在于：

1. 这个优化措施获取到的是一个时间范围（两个时间戳），而非一个确切的时间戳。
2. 由此导致，如果用户设置的时间范围与数据源返回的两个时间只有**部分重叠**，就会导致可能误判。

图示：

![](./images/202211100345.png)

黑线是用户设置的时间范围；红线和绿线都是数据源返回的时间范围。

**总结：**

数据源返回的时间范围要么在用户设置的时间范围之前，要么在中间，要么在之后。

如果数据源返回的时间范围包裹了用户设置的时间范围，或只是部分重叠，则数据不可采信。

下载器的判断逻辑是：

```js
return (时间戳 1 >= 用户设置的开始时间 && 时间戳 2 <= 用户设置的结束时间)
```

**问题 1：** 用户设置的时间范围起始值大于数据源里最后一个时间戳

这可以视为上图中的最上面的红线范围。由于此时数据源里只有开始时间，没有结束时间，所以是将第一条红线向右无限延伸的情况。

以简化的情况进行说明：

假如用户设置的时间为 2022/11/8 - 2022/11/9，某个作品正好处于这个区间。但是数据源里最后一个时间戳是 2022/11/5。

数据源里最后一个时间戳小于用户设置的起始时间，就会导致这个作品被排除。

现在进行了修复：如果作品 id 大于数据源里最后一条记录的 id，就将其视为检查通过。

**问题 2：** 用户设置的时间范围小于两条记录的时间范围

这个也是最上面的红线，只不过数据源里有完整的开始时间和结束时间。

假如数据源里两条相邻记录的时间相差 10 小时，如某一天的 0 - 10 点。而用户设置的时间范围为这一天的 6 - 8 点。

如果某个作品确实是处于 6 - 8 点，但是由于下载器只能返回 0 - 10 点，不符合用户设置的时间，就导致了这个作品被错误的排除。

现在进行了修复：如果用户设置的时间差小于两条记录的时间差，就将其视为检查通过。

**问题 3：** 用户设置的时间范围与两条记录的时间范围只有部分重叠

这是上图里第 2、3 条红线的情况。

假如有一个作品的发布时间是 16 点。用户设置的时间范围是 0 - 17 点，而相邻的两个时间戳是 8 - 18 点。

这就会错误的排除这个作品，因为数据源返回的开始时间或结束时间不符合用户设置的时间。

现在进行了修复：如果用户设置的时间范围与id对应的两条记录是部分重叠的，则将其视为检查通过。

-------------

可以看出，当发生数据不可采信的情况时，只会涉及相邻的两条记录（间隔为 10000 个作品）。

在一次抓取过程中，最多会在开头和结尾各发生一次数据不可采信的情况，等于最多会有 20000 个作品会因为数据不可采信而通过检查。为了避免误判，这个代价是值得的。

## 数据发掘

### 每 10,000 个图像作品所经过的时间

*数据保存在 `每隔 10000 个作品的发表时间之差.txt` 里。数据的单位是秒，图表里的单位则是小时。*

![](./images/作品发表时间的数据/image1.png)

可以看到间隔时间在一开始很大，到了后面则趋于稳定。然而，在中间靠后的部分，时间反而有小幅度的增加。

近期的间隔时间看起来在 10 小时左右。

由于数据项太多（一万多项），导致图表的线条密密麻麻地挤在一起，连成了一片，只能看不清楚。所以下面我会减少数据项，使图表更清晰。

### 最近每 10,000 个图像作品所经过的时间

从 `每隔 10000 个作品的发表时间之差.txt` 取最后 100 行数据，计算出它们的平均间隔为 35205 秒，9.8 小时。

![](./images/作品发表时间的数据/image3.png)

### 每 1,000,000 个图像作品所经过的时间

每隔 100 个数据来计算两个数据的时间差，这样就计算了每隔 1,000,000 个作品所经过的时间。

*数据保存在 `每隔 1000000 个作品的发表时间之差.txt` 里。数据的单位是秒，图表里的单位则是天。*

![](./images/作品发表时间的数据/image2.png)

可以看到，大约从 id 10,000,000 之后（2010 年初开始）就进入了较为稳定的阶段，每 50 天左右就会增加 1,000,000 个图像作品。但是中间确实有段时间的数值增加了（也就是新作品的投稿频率降低了）。

从最近（最后面）的一些数据来看，近来 pixiv 大约每隔 43 天增加 1,000,000 个图像作品。

依此计算，**最近**平均每天增加 23,000 个作品，平均每小时增加 970 个作品，平均每分钟增加 16 个作品。平均每隔 3.75  秒就有一个新作品发表。

### 数据源的精度（图像作品）

把每隔 1,000,000 个作品所经过的时间再除以 100，就等于以每 100 个数据为单位，计算它们的平均间隔时间。

*此时的单位是小时。*

![](./images/作品发表时间的数据/image4.png)

这个数据是每 10,000 个图像作品所经过的时间，**可以代表数据源的精度**，也就是相邻的两条数据的时间相差多少。

可以看到，在大部分情况下，时间间隔（精度）处于 10-15 小时之间。

如果去掉开头两个极端值，可以认为时间精度在 24 小时之内。

具体数值：（单位是小时，四舍五入为整数）

```
68
32
24
19
17
15
15
14
12
11
12
12
11
11
11
10
10
9
10
10
10
11
11
12
10
10
10
11
11
10
11
11
10
10
10
11
11
10
11
12
12
11
11
12
12
12
13
13
13
13
14
13
14
15
12
13
14
14
14
15
15
14
15
15
14
16
16
15
15
16
15
15
14
14
14
14
14
14
13
12
11
9
11
11
11
11
10
10
10
11
10
10
10
11
11
10
10
10
10
10
10
10
```

---------------

计算相邻两条数据之间间隔时间的代码：

```js
// data 就是数据源
const data =[]

const a = []
for (let index = 1; index < data.length; index++) {
  const num = data[index][1] - data[index - 1][1]
  // 把时间换算成秒
  a.push(num/1000)
}

const str = a.join('\n')
const blob = new Blob([str])
const url = URL.createObjectURL(blob)
window.open(url)
```
