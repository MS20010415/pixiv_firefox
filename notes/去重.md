# 设计目的

下载文件之后储存下载记录；下载文件之前可以查询下载记录，判断文件是否重复。

在下载面板上增加设置项目：

- 启用去重  deduplication
- 去重策略？宽松 严格    dupliStrategy strict loose 
- 清空去重数据？ clearDownloadRecords

宽松策略是只通过 id 判断是否重复，严格策略是同时结合文件名进行判断。

# 数据的存储方式：

## 数据库

去重数据（其实就是下载记录）单独存储在一个 IndexedDB 数据库中。

## 表

考虑到查询效率，这里做了分表。

根据 pixiv 作品 id 开头的数字，分成了 1-9 共 9 个表。当存储或查询时，根据作品 id 去对应的表里查询。

这样做是为了减少每个表里的数据量，这样在查询时可以避免不必要的查询，提高效率。

不过现实不会那么理想，因为数据的分布可能不是平均的。大家最常下载的应该是最近的作品，目前 pixiv 作品的 id 是 8000 w 多，所以表 8 可能存储的数据最多。

## 数据

每下载成功一个文件，添加它对应的下载记录。（下载失败的文件、跳过下载的文件不存储到下载记录里）

记录的数据如：

```
{
  id:'82432085',
  n:'光崎/82432085_p0.png'
}
```

`id` 字段是作品 id。

`n` 字段是生成的文件名。文件名可以很长，其长度不好估算。

假设一条数据占据的存储空间为 `500 B` 左右（往大了算），那么 `1 GiB` 空间可以存储约 `200 w` 条记录。

目前 pixiv 的作品 id 是 8 位数。如果只算图片作品，每个分表的数据最大量可以达到约 1111w。如果加上小说，那么会更多一些。不过小说的 id 总数比图片的少很多。

# IndexedDB 相关知识

## 额度控制

浏览器的本地存储的额度控制参考这里：

https://developer.mozilla.org/zh-CN/docs/Web/API/IndexedDB_API/Browser_storage_limits_and_eviction_criteria

根据这里面的说法，如果本地存储占据的硬盘空间达到上限，浏览器会依次清理掉最久没有被使用的源的数据。似乎一个域名就是一个源（子域名不同则视为不同的网站）。浏览器清理存储空间的时候是按源为单位的，所以如果清理到 pixiv.net 的话，其下所有数据库都会被删除。

## 由用户清理数据

当用户清除浏览数据时，选择 **Cookie 及其它网站数据** 会清理本地存储，包括 localstorage、WebSQL、IndexedDB 等。

本程序的去重功能设置里，提供了一个按钮，可以清除保存的去重数据。