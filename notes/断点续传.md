更新： 2020/08/25

在做断点续传的时候，Chrome 稳定版的版本号大概是 82，83，IndexedDB 单条记录的数据有体积上限，约为 **127 MiB**。不过 Reinford 发现，在 84 版本里，这个上限已经大大提高，测试存储 **1.2 GiB** 已经成功，更大的体积因为我内存不大所以没能完成测试，不知道新的上限是多少。

当初因为有 127 MiB 的限制，所以当数据量大的时候需要分批存储。现在这个限制大大提高了，不过我并没有取消分批存储的机制。一些原因如下：

1. 新版本的单条记录存储上限是多少？会不会仍然会遇到超出上限的情况？
2. 存储时内存占用很大，比如存储 1 GiB 的记录时，Chrome 可能会占用 5 GiB 左右的内存。所以即使没有达到新的上限，也可能遇到内存溢出，导致存储失败。
3. 单条记录体积很大时，存储花费的时间很长，消耗内存较大，页面卡顿明显。而之前的分批存储就没有这么卡顿，所以用户体验上来看还是分批存储比较好。
4. 旧版本的浏览器估计仍然有 127 MiB 的限制，考虑到仍然会有一些人使用旧的浏览器，所以这部分目前不应该进行改动。

ps: Reinford 测试了 Chrome 目前使用单个变量存储字符串的话，字符串的上限大概是 400 MiB。
--------

使用 IndexedDB 保存抓取结果，用来断点续传。目前是建立了三个表：

# taskMeta

抓取结果的元数据，并不保存实际数据。因为实际数据太大的话需要分批存储。


```
{
id:时间戳,
url:'xxxxx',
part:number
}
```

- id 不重复，作为主键。
- url   网址，不包含 hash 部分。一个网址（页面）里只会保存最新一次的抓取结果。
- part  记录数据被分成了几个部分

## 处理时机

抓取完毕时，保存抓取结果的元数据

下载完毕后，删除部分数据。

页面加载时，读取该网址下有没有任务，如果有，则加载这个任务的数据，恢复进度。并且将下载面板显示的选项卡设置为“下载”部分。

# taskData

存储抓取结果的所有数据。

```
{
id:时间戳 + part,
data:result[]
}
```

- id 任务的 id，加上索引号使 id 唯一
- data  这个部分里储存的任务的数据

如果抓取结果太多，一次抓取的结果可能要分多个记录进行存储。

下载完毕后，删除部分数据。

# taskStates

下载过程中，每下载完一个作品，保存下载状态到表 taskStates 里。

也可以考虑改为每隔一段时间存储。

```
{
  id:时间戳,
  states:(-1,0,1)[]
}
```

- id 时间戳，使用 taskMeta 的时间戳
- states 本次任务中所有文件的下载状态

下载完毕后，删除部分数据。

# 压力测试

2020-07-13，抓取我所有的关注用户的作品。

```
当前有 2656 个用户
当前有 420438 个作品
已获取 996270 个文件网址
抓取完毕！
```

抓取约花费了 5 个小时，每秒约完成 24 个请求。

统计不同类型的文件个数：

```
插画  714745
漫画  267419
动画  13370
小说  736
```

没能保存到 IndexedDB 里，IndexedDB 抛出了一个错误事件：

```
Event {
  target: IDBRequest {
    error: DOMException {
      code: 0
      message: "The serialized keys and/or value are too large (size=625726452 bytes, max=133169152 bytes)."
      name: "UnknownError"
    }
  }
}
```

提示信息说序列化之后的键值对太大，625726452 约等于 **600 MiB**，而浏览器限制的最大值 133169152 约等于 **127 MiB**。经查，这个限制 6 年前就有了，这么多年也没加大容量，唉。

这个限制是单条数据的限制，而不是数据库或表的体积上限。现在通过分批存储，解决了这个问题。

分析一下数据的体积：

小说的文件以 blob 类型保存在抓取结果里，所有小说的 blob 体积总共有 `99994522` 字节，约为 95 MiB。

上面 IndexedDB 说的“序列化后”的体积，不知道和这些数据在页面内存中的体积是否一致。如果认为两者相同，则每个抓取结果除 blob 之外的数据体积为 0.5 KiB。但如果在页面内存中的体积更大一些的话，可能为 0.7 - 0.8 KiB。

浏览器会把 IndexedDB 里的数据保存到本地文件，比如 Chrome 把 pixiv 的数据保存到了这个文件夹里：

```
%userprofile%\AppData\Local\Google\Chrome\User Data\Default\IndexedDB\https_www.pixiv.net_0.indexeddb.leveldb
```

感觉保存到本地的文件是经过压缩的，没有原本那么大。

## 存取时间

模拟了 166 W 条抓取结果的情况，存储用了接近 40 秒，恢复用了接近 20 秒。